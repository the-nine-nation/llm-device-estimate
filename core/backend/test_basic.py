#!/usr/bin/env python3
"""
åŸºç¡€åŠŸèƒ½æµ‹è¯•
è¿è¡Œæ­¤è„šæœ¬éªŒè¯åç«¯æ ¸å¿ƒåŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ°Python path
sys.path.insert(0, os.path.join(os.path.dirname(__file__)))

def test_imports():
    """æµ‹è¯•å¯¼å…¥æ˜¯å¦æ­£å¸¸"""
    print("ğŸ” æµ‹è¯•æ¨¡å—å¯¼å…¥...")
    
    try:
        from app.models.common import ModelInfo, PrecisionType, ModelSize
        from app.models.training import TrainingRequest, TrainingMethod
        from app.models.inference import InferenceRequest, InferenceBackend
        from app.services.model_registry import ModelRegistry
        from app.services.calculator.training_calc import TrainingCalculator
        from app.services.calculator.inference_calc import InferenceCalculator
        print("âœ… æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return False


def test_model_registry():
    """æµ‹è¯•æ¨¡å‹æ³¨å†Œè¡¨"""
    print("\nğŸ” æµ‹è¯•æ¨¡å‹æ³¨å†Œè¡¨...")
    
    try:
        registry = ModelRegistry()
        
        # æµ‹è¯•è·å–æ‰€æœ‰æ¨¡å‹
        models = registry.get_all_models()
        print(f"âœ… æ¨¡å‹æ³¨å†Œè¡¨åŒ…å« {len(models)} ä¸ªé¢„å®šä¹‰æ¨¡å‹")
        
        # æµ‹è¯•è·å–ç‰¹å®šæ¨¡å‹
        llama_7b = registry.get_model_info("llama-7b")
        print(f"âœ… æˆåŠŸè·å–LLaMA 7Bæ¨¡å‹ä¿¡æ¯: {llama_7b.name}")
        
        # æµ‹è¯•æŒ‰ç³»åˆ—è·å–æ¨¡å‹
        llama_models = registry.get_models_by_family("llama")
        print(f"âœ… LLaMAç³»åˆ—åŒ…å« {len(llama_models)} ä¸ªæ¨¡å‹")
        
        return True
    except Exception as e:
        print(f"âŒ æ¨¡å‹æ³¨å†Œè¡¨æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_training_calculator():
    """æµ‹è¯•è®­ç»ƒè®¡ç®—å™¨"""
    print("\nğŸ” æµ‹è¯•è®­ç»ƒè®¡ç®—å™¨...")
    
    try:
        from app.models.training import TrainingRequest, TrainingMethod, OptimizerType
        from app.models.common import PrecisionType
        
        # åˆ›å»ºæµ‹è¯•è¯·æ±‚
        request = TrainingRequest(
            model_id="llama-7b",
            training_method=TrainingMethod.LORA,
            precision=PrecisionType.FP16,
            batch_size=4,
            sequence_length=2048,
            optimizer=OptimizerType.ADAMW
        )
        
        calculator = TrainingCalculator()
        result = calculator.calculate(request)
        
        print(f"âœ… è®­ç»ƒè®¡ç®—æˆåŠŸ:")
        print(f"   - æ€»æ˜¾å­˜éœ€æ±‚: {result.total_memory_gb:.2f} GB")
        print(f"   - æ¨¡å‹æƒé‡: {result.model_memory_gb:.2f} GB")
        print(f"   - æ¿€æ´»å€¼: {result.activation_memory_gb:.2f} GB")
        print(f"   - æœ€å°‘GPUæ•°é‡: {result.min_gpu_count}")
        
        return True
    except Exception as e:
        print(f"âŒ è®­ç»ƒè®¡ç®—å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_inference_calculator():
    """æµ‹è¯•æ¨ç†è®¡ç®—å™¨"""
    print("\nğŸ” æµ‹è¯•æ¨ç†è®¡ç®—å™¨...")
    
    try:
        from app.models.inference import InferenceRequest, InferenceBackend, QuantizationMethod
        from app.models.common import PrecisionType
        
        # åˆ›å»ºæµ‹è¯•è¯·æ±‚
        request = InferenceRequest(
            model_id="llama-7b",
            backend=InferenceBackend.VLLM,
            precision=PrecisionType.FP16,
            quantization=QuantizationMethod.NONE,
            max_batch_size=8,
            max_sequence_length=2048
        )
        
        calculator = InferenceCalculator()
        result = calculator.calculate(request)
        
        print(f"âœ… æ¨ç†è®¡ç®—æˆåŠŸ:")
        print(f"   - æ€»æ˜¾å­˜éœ€æ±‚: {result.total_memory_gb:.2f} GB")
        print(f"   - KV Cache: {result.kv_cache_memory_gb:.2f} GB")
        print(f"   - é¢„ä¼°ååé‡: {result.estimated_throughput:.0f} tokens/s")
        print(f"   - æœ€å¤§å¹¶å‘è¯·æ±‚: {result.max_concurrent_requests}")
        
        return True
    except Exception as e:
        print(f"âŒ æ¨ç†è®¡ç®—å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹åç«¯åŸºç¡€åŠŸèƒ½æµ‹è¯•\n")
    
    tests = [
        test_imports,
        test_model_registry,
        test_training_calculator,
        test_inference_calculator
    ]
    
    passed = 0
    failed = 0
    
    for test in tests:
        if test():
            passed += 1
        else:
            failed += 1
    
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
    print(f"âœ… é€šè¿‡: {passed}")
    print(f"âŒ å¤±è´¥: {failed}")
    
    if failed == 0:
        print(f"\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼åç«¯åŸºç¡€åŠŸèƒ½æ­£å¸¸å·¥ä½œã€‚")
    else:
        print(f"\nâš ï¸  æœ‰ {failed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³æ¨¡å—ã€‚")
    
    return failed == 0


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 